name: Linux benchmark tests / LLVM 10.0

on:
  pull_request:
    branches: ['master']
  push:
    branches:
      - 'master'
      - '**test_bench**'

env:
  LLVM_VERSION: "10.0"
  LLVM_REPO: https://github.com/dbabokin/llvm-project
  LLVM_TAR: llvm-10.0.1-ubuntu16.04-Release+Asserts-x86.arm.wasm.tar.xz

jobs:
  linux-build:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
      with:
        submodules: true

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install bison flex libc6-dev-i386 g++-multilib lib32stdc++6 ncurses-dev
        wget $LLVM_REPO/releases/download/llvm-$LLVM_VERSION-ispc-dev/$LLVM_TAR
        tar xvf $LLVM_TAR 
        echo "PATH=${GITHUB_WORKSPACE}/bin-$LLVM_VERSION/bin:$PATH" >> $GITHUB_ENV

    - name: Check environment
      run: |
        ./check_env.py
        which -a clang
        cat /proc/cpuinfo

    - name: Build package
      run: |
        cmake -B build -DISPC_PREPARE_PACKAGE=ON -DISPC_INCLUDE_BENCHMARKS=ON -DBENCHMARK_ENABLE_INSTALL=ON
        cmake --build build --target package -j4

    - name: Sanity testing (make check-all, make test)
      run: |
        cd build
        bin/check_isa
        bin/ispc --support-matrix
        make check-all
        make ispc_benchmarks && make test

    - name: Upload package
      uses: actions/upload-artifact@v2
      with:
        name: ispc_llvm10_linux
        path: build/ispc-trunk-linux.tar.gz

  benchmarks:
    continue-on-error: true
    runs-on: [self-hosted, linux, bench]
    needs: linux-build
    steps:
    - name: Download package
      uses: actions/download-artifact@v2
      with:
        name: ispc_llvm10_linux
    - name: Install dependencies and unpack artifacts
      run: |
        tar xvf ispc-trunk-linux.tar.gz
        echo "ADD_PATH=${GITHUB_WORKSPACE}/ispc-trunk-linux/bin:$ADD_PATH" >> $GITHUB_ENV
        echo "LLVM_HOME=${GITHUB_WORKSPACE}" >> $GITHUB_ENV
        echo "ISPC_HOME=${GITHUB_WORKSPACE}"  >> $GITHUB_ENV
    - name: Check environment
      run: cat /proc/cpuinfo
    - name: Tune system for benchmarking
      run: curl http://$StabilizerServer:7373/acquire
      if: always()
    - name: Running benchmarks
      run: |
        mkdir -p out
        export LD_LIBRARY_PATH=../lib
        for exec in $(find . -type f -perm -u+x); do $exec --benchmark_out=out/$(basename $exec).json $BENCH_SETTINGS ; done
      working-directory: ispc-trunk-linux/benchmarks/
      env:
        BENCH_SETTINGS: '--benchmark_repetitions=10'
    - name: Reset system performance
      run: curl http://$StabilizerServer:7373/release
      if: always()
    - name: Upload results
      uses: actions/upload-artifact@v2
      with:
        name: ispc_llvm10_linux_bench_results
        path: ispc-trunk-linux/benchmarks/out/*.json
    - name: Clean self-hosted runner
      run: rm -rf ${GITHUB_WORKSPACE:?}/* ${HOME:?}/* 
      if: always()

  calcite:
    continue-on-error: true
    needs: benchmarks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Download benchmarks results
        uses: actions/download-artifact@v2
        with:
          name: ispc_llvm10_linux_bench_results
      - name: Upload bench datasets to calcite
        working-directory: .calcite
        run: |
          npm ci
          npx calcite upload calcite.config.js
        env:
          BENCH_OUTPUT_FILES: ${{github.workspace}}
          CALCITE_TOKEN: ${{ secrets.CALCITE_TOKEN }}
      - name: Trigger calcite workflow
        if: github.event_name == 'pull_request' && success()
        working-directory: .calcite
        run: npx calcite trigger $(git cat-file -p HEAD | awk 'NR > 1 {if(/^parent/){print $2;}{exit}}') -tt pullrequest
        env:
          CALCITE_TOKEN: ${{ secrets.CALCITE_TOKEN }}
